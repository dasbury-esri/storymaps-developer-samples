{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Story protector\n",
    "This notebook crawls the items, maps, dashboards, scenes, within a story and delete protects those items and their content provided it is within your org.\n",
    "\n",
    "## How to run\n",
    "1. Provide the `itemId` of your story to the `story_id` parameter below.\n",
    "2. Configure `delete_protect` to set whether you would like to apply **delete protection** to the story and all of the content items found within it. **True** = protect items, **False** = leave unprotected.\n",
    "3. Configure `share` to set whether you would like to perform a bulk update of the sharing permissions for the story and all of its content.\n",
    "4. If `share` is set to **True**, provide a sharing level 'private', 'org', or 'public'\n",
    "5. Once parameters have been configured, click 'Cell' > 'Run All' in the menu bar above.\n",
    "6. Scroll down in the notebook and inspect the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## These are the input parameters\n",
    "story_id = '' # <-- Paste your story itemId here\n",
    "delete_protect = True # <- toggle the delete protection ON (True) or OFF (False)\n",
    "## If the `share` setting below is False then this setting won't be configured and the `share_level` will also be ignored.\n",
    "share = False # <- if you want to bulk share the content set this to True otherwise, False\n",
    "share_level = 'public' # <- set this to ['private', 'org', or 'public']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script setup\n",
    "These are functions that do smaller tasks within the main script. For instance, some crawl specific items like dashboards or webmaps and other crawl nested group layers within a webmap.\n",
    "\n",
    "Storing them here is just easier and makes bits of code re-usable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arcgis.gis import GIS\n",
    "from arcgis.gis import Item\n",
    "import re # import regex\n",
    "import pandas as pd\n",
    "from typing import List, Set, Union\n",
    "\n",
    "# Set Pandas dataframe display options\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns',500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty container to eventually hold all of the items found within the story\n",
    "result_list = []\n",
    "\n",
    "# Define a crawler helper to fetch the item info\n",
    "def getResourceInfo(resourceId, itemList):\n",
    "    query = f\"id: {resourceId}\"\n",
    "    resource = gis.content.advanced_search(query=query, max_items=-1, as_dict=True)['results']\n",
    "    if len(resource) > 0:\n",
    "        itemList += resource\n",
    "\n",
    "# Define a crawler helper to fetch the item info\n",
    "def query_found_items(found_items, item_list):\n",
    "    for item_id in found_items:\n",
    "        query = f\"id: {item_id}\"\n",
    "        item_results = gis.content.advanced_search(query=query, max_items=-1, as_dict=True)['results']\n",
    "        if len(item_results) > 0:\n",
    "            item_list += item_results\n",
    "    return item_list\n",
    "        \n",
    "\n",
    "def get_item_data(item: Item):\n",
    "    \"\"\"\n",
    "    Fetches data for a given ArcGIS item, handling different resource types.\n",
    "\n",
    "    Args:\n",
    "        item (Item): The ArcGIS item to fetch data for.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the item data and any related data.\n",
    "    \"\"\"\n",
    "    item_data = item.get_data(try_json=True)\n",
    "    if item.type in [\"StoryMap\", \"StoryMap Theme\"]:\n",
    "        # Should only be relevant to StoryMaps\n",
    "        try:\n",
    "            resources = [resource[\"resource\"] for resource in item.resources.list()]\n",
    "            has_published_data = \"published_data.json\" in resources\n",
    "            draft_id = None\n",
    "            for keyword in item.typeKeywords:\n",
    "                if keyword.startswith(\"smdraftresourceid\"):\n",
    "                    draft_id = keyword.split(\":\")[1]\n",
    "            if has_published_data and not draft_id:\n",
    "                return (item.resources.get(\"published_data.json\", try_json=True), None)\n",
    "            elif draft_id and not has_published_data:\n",
    "                return (item.resources.get(f\"{draft_id}\", try_json=True), None)\n",
    "            elif draft_id and has_published_data:\n",
    "                return (\n",
    "                    item.resources.get(f\"{draft_id}\", try_json=True),\n",
    "                    item.resources.get(\"published_data.json\", try_json=True),\n",
    "                )\n",
    "            else:\n",
    "                return (item.resources.get(\"draft.json\", try_json=True), None)\n",
    "        except Exception as e:\n",
    "            return (None, None)\n",
    "    return (item_data, None)\n",
    "\n",
    "def find_all_possible_ids(json_string: str):\n",
    "    \"\"\"\n",
    "    Extracts all possible item IDs from a JSON string using regex.\n",
    "\n",
    "    Args:\n",
    "        json_string (str): The JSON string to search for IDs.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of found item IDs.\n",
    "    \"\"\"\n",
    "    return re.findall(r\"[\\\"\\'\\/]([a-zA-Z0-9]{32})[\\\"\\'\\/]\", json_string)\n",
    "    \n",
    "def get_related_items_for_id(\n",
    "    gis_con: GIS,\n",
    "    item_id: str,\n",
    "    relation_path: List[str] = [],\n",
    "    relations_in_process: List[str] = []\n",
    "):\n",
    "    \"\"\"\n",
    "    Fetches related items for a given item ID and updates the related items DataFrame.\n",
    "    This function attempts to fetch an item by its ID up to three times. If successful, it processes the item to find its related items and updates the provided DataFrames accordingly. It also handles cyclic dependencies and ensures that items are not processed multiple times.\n",
    "    Args:\n",
    "        gis_con (GIS): The GIS connection object.\n",
    "        item_id (str): The ID of the item to fetch and process.\n",
    "        related_items_df (pd.DataFrame): DataFrame to store information about related items.\n",
    "        missed_items_df (pd.DataFrame): DataFrame to store information about items that could not be fetched.\n",
    "        main_ancestors (Set[str]): Set to store the IDs of main ancestor items.\n",
    "        base_ancestor (Union[Item, None], optional): The base ancestor item. Defaults to None.\n",
    "        relation_path (List[str], optional): List to track the relation path of items. Defaults to an empty list.\n",
    "        relations_in_process (List[str], optional): List to track items that are currently being processed. Defaults to an empty list.\n",
    "    Returns:\n",
    "        related_items\n",
    "    \"\"\"\n",
    "\n",
    "    valid_item = None\n",
    "    # Attempt to fetch the item up to 3 times\n",
    "    for tries in range(3):\n",
    "        try:\n",
    "            valid_item = Item(gis_con, item_id)\n",
    "            break  # Exit loop on successful fetch\n",
    "        except Exception as e:\n",
    "            # print(f\"Error fetching item {item_id}: {e}. Retrying ({tries+1}/3)...\")\n",
    "            time.sleep(1)  # Adding delay before retry\n",
    "            # if tries == 2:\n",
    "            #     missed_items_df.loc[uuid.uuid4()] = [item_id, None, None, str(e)]\n",
    "    # Copy the current relation path for further processing\n",
    "    new_relation_path = relation_path.copy()\n",
    "    \n",
    "    # Only add the valid item's ID to the relation path if not handling the main ancestor\n",
    "    if valid_item:\n",
    "        new_relation_path.append(valid_item.itemid)\n",
    "    # If valid_item was successfully fetched, and all previous conditions are met, proceed to fetch related items for this item\n",
    "    if valid_item:\n",
    "        items_related_to_valid_item = set()\n",
    "        relations_in_process.append(valid_item.itemid)\n",
    "        valid_item_data = get_item_data(valid_item)\n",
    "        # If the first part of the fetched data is not empty\n",
    "        if valid_item_data[0] is not None or valid_item_data[0] != {}:\n",
    "            related_json_string = str(valid_item_data[0])\n",
    "            related_ids = find_all_possible_ids(related_json_string)\n",
    "            [items_related_to_valid_item.add(related_id) for related_id in related_ids]\n",
    "            related_items = list(items_related_to_valid_item)\n",
    "        # If the second part of the fetched data is not empty (only relevant to StoryMaps), and considers draft related items\n",
    "        if valid_item_data[1] is not None or valid_item_data[1] != {}:\n",
    "            related_json_string = str(valid_item_data[1])\n",
    "            related_ids = find_all_possible_ids(related_json_string)\n",
    "            [items_related_to_valid_item.add(related_id) for related_id in related_ids]\n",
    "            related_items = list(items_related_to_valid_item)\n",
    "        # Iterate over each related ID found\n",
    "        for related_id in items_related_to_valid_item:\n",
    "            # Recursively call the function to find related items for each related ID\n",
    "            get_related_items_for_id(\n",
    "                gis_con,\n",
    "                related_id,\n",
    "                new_relation_path,\n",
    "            )\n",
    "    return related_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content discovery\n",
    "The script below crawls the story data and calls the helper functions defined above to subsequently crawl the contents of items found within the story.\n",
    "\n",
    "Once this block runs the script will return a table showing all the items found within the story."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GIS\n",
    "gis = GIS(\"home\")\n",
    "\n",
    "# Define the main story crawler function\n",
    "# Crawl the story to find items and record their item_id\n",
    "story = Item(gis, story_id)\n",
    "\n",
    "story_data = get_item_data(story)\n",
    "items_in_story = list(set(find_all_possible_ids(str(story_data))))\n",
    "\n",
    "for index, item_id in enumerate(items_in_story):\n",
    "    # print(f\"Processing item {index} with id {item_id}\")\n",
    "    try:\n",
    "        related_items = get_related_items_for_id(\n",
    "            gis, item_id, items_in_story\n",
    "        )\n",
    "        for related_item in related_items:\n",
    "            items_in_story.append(related_item)\n",
    "    except Exception as e:\n",
    "        # print(str(e))\n",
    "        pass\n",
    "        \n",
    "items_found = query_found_items(items_in_story, result_list)\n",
    "# Turn the contents from the story into a dataframe\n",
    "items_df = pd.DataFrame(items_found)\n",
    "# Create a convenient subset of columns\n",
    "items_df = items_df[['id', 'owner', 'created', 'isOrgItem', 'modified', 'title', 'type','protected', 'access']] # drop columns except these\n",
    "# Remove duplicate items\n",
    "items_df = items_df.drop_duplicates(subset='id') # drop duplicate items\n",
    "# Filter to only show those items that are within the 'home' org\n",
    "items_df = items_df.loc[items_df['isOrgItem'] == True]\n",
    "\n",
    "#Preview\n",
    "items_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Protect the items\n",
    "Using the table of items above, this next block will loop through those items and perform to desired protection and sharing updates.\n",
    "\n",
    "Once complete, this block will report back an updated table of all the items for review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Now that we have a list of items we'll protect them from deletion and optionally make them public\n",
    "id_list = items_df['id'].tolist()\n",
    "\n",
    "# Function to perform the protection and sharing\n",
    "def update_item_properties(item, protection, share, level):\n",
    "    i = gis.content.get(item)\n",
    "    i.protect(enable = protection)\n",
    "    if share:\n",
    "        i.update(item_properties={\"access\": level})\n",
    "\n",
    "# Update the settings for each item\n",
    "for item in id_list:\n",
    "    try:\n",
    "        update_item_properties(item, delete_protect, share, share_level)\n",
    "    except:\n",
    "        print('Error: Could not update \"{0}\".'.format(item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Review the results\n",
    "Wait a few moments after running the above. This last cell will query those items that were protected and present an updated table where you can confirm that things were protected/shared as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Reset the container\n",
    "itemList = []\n",
    "\n",
    "# Re-query the items to refresh the properties\n",
    "for item in id_list:\n",
    "    getResourceInfo(item, itemList)\n",
    "\n",
    "# Turn the contents from the story into a dataframe\n",
    "items_df = pd.DataFrame(itemList)\n",
    "# Create a convenient subset of columns\n",
    "items_df = items_df[['id', 'owner', 'created', 'isOrgItem', 'modified', 'title', 'type','protected', 'access']] # drop columns except these\n",
    "items_df"
   ]
  }
 ],
 "metadata": {
  "esriNotebookRuntime": {
   "notebookRuntimeName": "ArcGIS Notebook Python 3 Standard",
   "notebookRuntimeVersion": "9.0"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
